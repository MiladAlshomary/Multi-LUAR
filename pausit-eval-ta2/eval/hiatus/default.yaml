name: test
output_path: /mnt/output/metrics.json
ta1:
  performer_config_path: /mnt/input/featurespace/predictions/performer-config.yaml 
  features_dataset: /mnt/input/featurespace/ predictions/ example_TA1_features_run0/ 
  resample_queries: /mnt/input/featurespace/data/example_TA1_input_queries.jsonl 
  resample_candidates: /mnt/input/featurespace/data/example_TA1_input_candidates.jsonl 
  ground_truth: /mnt/input/featurespace/groundtruth/example_TA1-groundtruth.jsonl 
  top_k: [1, 8, 30, all]
  compute_metrics_at_distance: True
  stylistic_consistency: False
ta2:
  performer_config_path: /mnt/input/attribution/predictions/performer-config.yaml
  scores: /mnt/input/attribution/predictions/example_TA2_query_candidate_attribution_scores_run0.npy
  scores_candidate_labels: /mnt/input/attribution/predictions/example_TA2_query_candidate_attribution_candidate_labels_run0.txt
  scores_query_labels: /mnt/input/attribution/predictions/example_TA2_query_candidate_attribution_query_labels_run0.txt
  ground_truth: /mnt/input/attribution/groundtruth/example_TA2_groundtruth.npy
  ground_truth_candidate_labels: /mnt/input/attribution/groundtruth/example_TA2_candidate-labels.txt
  ground_truth_query_labels: /mnt/input/attribution/groundtruth/example_TA2_query-labels.txt
  far_target:
  - 0.1
  - 0.05
  - 0.01
  metrics:
  - all
ta3:
  text_field: fullText
  privacy:
    ground_truth: /mnt/input/attribution/groundtruth/example_TA2_groundtruth.npy
    ground_truth_candidate_labels: /mnt/input/attribution/groundtruth/example_TA2_candidate-labels.txt
    ground_truth_query_labels: /mnt/input/attribution/groundtruth/example_TA2_query-labels.txt
    metric_name: Delta Equal Error Rate
    ta2_system_outputs:
    - ta2_system_name: baseline-01
      in_context_privacy: true
      performer_config_path: /mnt/input/attribution/predictions/performer-config.yaml
      original_scores: /mnt/input/attribution/predictions/example_TA2_query_candidate_attribution_scores_run0.npy
      original_scores_candidate_labels: /mnt/input/attribution/predictions/example_TA2_query_candidate_attribution_candidate_labels_run0.txt
      original_scores_query_labels: /mnt/input/attribution/predictions/example_TA2_query_candidate_attribution_query_labels_run0.txt
      privatized_scores: /mnt/input/attribution/privatized-predictions/example_TA2_query_candidate_attribution_scores_run0.npy
      privatized_scores_candidate_labels: /mnt/input/attribution/privatized-predictions/example_TA2_query_candidate_attribution_candidate_labels_run0.txt
      privatized_scores_query_labels: /mnt/input/attribution/privatized-predictions/example_TA2_query_candidate_attribution_query_labels_run0.txt
  sense:
    metric_name: gpt4eval
    original_dataset: /mnt/input/privacy/data/example_TA3_input_queries.jsonl
    privatized_dataset: /mnt/input/privacy/predictions/example_TA3_privatized_queries_run0.jsonl
    criteria_path: /data/criteria.json
