{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98add410-2397-4016-a873-968289bfacb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39967725-2cd2-4da3-8e97-79546fd8626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/swordfish-pool2/milad/hf-cache'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/mnt/swordfish-pool2/milad/hf-cache'\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f92b73-a37d-443b-90ac-e6f131417e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from src.utilities.mluar_utils import *\n",
    "from src.datasets import utils\n",
    "from src.arguments import create_argument_parser\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68524a3c-6085-46ff-8639-45985108e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce, repeat\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import pickle as pkl\n",
    "import tabulate\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5979105-cb91-4941-a198-4cf18e2f5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = create_argument_parser()\n",
    "params.sanity = None\n",
    "params.episode_length=16\n",
    "params.model_type='roberta'\n",
    "params.text_key = 'syms'\n",
    "params.time_key='hours'\n",
    "params.suffix=''\n",
    "params.token_max_length=32\n",
    "params.use_random_windows=False\n",
    "params.mask_bpe_percentage=0\n",
    "params.pin_memory=False\n",
    "params.num_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61abce0-9a44-4819-9999-27578cc60775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI_LUAR_PATH =  \"/mnt/swordfish-pool2/milad/Multi-LUAR/data/multi-luar-reddit-model/\"\n",
    "MULTI_LUAR_PATH =  \"/mnt/swordfish-pool2/milad/Multi-LUAR/data/multi-luar-all-model/\"\n",
    "LUAR_PATH       =  \"/mnt/swordfish-pool2/milad/Multi-LUAR/data/reproduced-luar/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abc7098f-1fd3-42e8-bcec-af94d8211d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load models\n",
    "multiluar_model = AutoModel.from_pretrained(MULTI_LUAR_PATH, trust_remote_code=True)\n",
    "luar_model = AutoModel.from_pretrained(LUAR_PATH, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rrivera1849/LUAR-MUD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e883083-2487-4206-b7aa-7062916e01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following two functions are taken from src/models/lightning_trainer.py\n",
    "def validation_collate_fn(batch):\n",
    "    \"\"\"Some validation datasets have authors with less than < 16 episodes. \n",
    "       When batching, make sure that we don't run into stacking problems. \n",
    "    \"\"\"\n",
    "\n",
    "    data, author = zip(*batch)\n",
    "\n",
    "    author = torch.stack(author)\n",
    "\n",
    "    # Minimum number of posts for an author history in batch\n",
    "    min_posts = min([d[0].shape[1] for d in data])\n",
    "    # If min_posts < episode length, need to subsample\n",
    "    if min_posts < 16:\n",
    "        data = [torch.stack([f[:, :min_posts, :] for f in feature])\n",
    "                for feature in zip(*data)]\n",
    "    # Otherwise, stack data as is\n",
    "    else:\n",
    "        data = [torch.stack([f for f in feature])\n",
    "                for feature in zip(*data)]\n",
    "\n",
    "    return data, author\n",
    "\n",
    "def test_dataloader(params):\n",
    "    \"\"\"Returns the validation DataLoader.\n",
    "    \"\"\"\n",
    "    # to counteract different episode sizes during validation / testing\n",
    "    batch_size = 1 if params.dataset_name in [\"raw_amazon\", \"pan_paragraph\", \"hrs\"] else params.batch_size\n",
    "    \n",
    "    queries, targets = utils.get_val_or_test_dataset(params, 'test', only_queries=False)\n",
    "\n",
    "    q_data_loader = DataLoader(\n",
    "        queries,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=params.pin_memory,\n",
    "        num_workers=params.num_workers,\n",
    "        collate_fn=validation_collate_fn\n",
    "    )\n",
    "\n",
    "    t_data_loader = DataLoader(\n",
    "        targets,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=params.pin_memory,\n",
    "        num_workers=params.num_workers,\n",
    "        collate_fn=validation_collate_fn\n",
    "    )\n",
    "\n",
    "    return q_data_loader, t_data_loader, queries, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "312ce32d-b8ed-44c0-abbd-6e91784a9d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(test_data_loader):\n",
    "    luar_embeddings = []\n",
    "    mluar_embeddings = []\n",
    "    author_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(test_data_loader)):\n",
    "            data, author = batch[0], batch[1]\n",
    "            \n",
    "            luar_embedding = luar_model(data[0].squeeze(0), data[1].squeeze(0))\n",
    "            luar_embeddings.append(luar_embedding)\n",
    "        \n",
    "            mluar_embedding = multiluar_model(data[0].squeeze(0), data[1].squeeze(0))\n",
    "            mluar_embedding = rearrange(mluar_embedding, 'l b d -> b l d')\n",
    "            mluar_embeddings.append(mluar_embedding)\n",
    "    \n",
    "            author_labels.append(author)\n",
    "        luar_embeddings = torch.stack(luar_embeddings)\n",
    "        mluar_embeddings = torch.stack(mluar_embeddings).squeeze(1)\n",
    "\n",
    "    return luar_embeddings, mluar_embeddings, author_labels\n",
    "\n",
    "def evaluate_embeddings(q_embed, t_embed, q_mluar_embed, t_mluar_embed,  q_labels, t_labels, domain = 'pan'):\n",
    "    results = []\n",
    "    \n",
    "    luar_sims = compute_similarities(q_embed, t_embed)\n",
    "    labels_matrix = np.array([[int(x == y) for y in t_labels] for x in q_labels])\n",
    "    luar_eer, luar_mrr   = eer(luar_sims, labels_matrix), compute_mrr(luar_sims, q_labels, t_labels)\n",
    "    \n",
    "    results.append(['LUAR', domain, luar_eer, luar_mrr])\n",
    "    results.append(['+++', '+++', '+++', '+++'])\n",
    "    \n",
    "    muti_luar_layers_sims = np.stack([compute_similarities(q_mluar_embed, t_mluar_embed, layer=i) for i in range(7)])\n",
    "    \n",
    "    muti_luar_layers_sims_ablated = np.mean(muti_luar_layers_sims, 0)\n",
    "    mluar_eer, mluar_mrr = eer(muti_luar_layers_sims_ablated, labels_matrix), compute_mrr(muti_luar_layers_sims_ablated,  q_labels, t_labels)\n",
    "    results.append(['MLUAR', domain, mluar_eer, mluar_mrr])\n",
    "    results.append(['--', '--', '--', '--'])\n",
    "    \n",
    "    # Ablation study\n",
    "    for selector in [[0,1], [0,1,2],[3,4,5], [5,6],[6]]:\n",
    "        muti_luar_layers_sims_ablated = np.mean(muti_luar_layers_sims[selector, :, :], 0)\n",
    "        mluar_eer, mluar_mrr = eer(muti_luar_layers_sims_ablated, labels_matrix), compute_mrr(muti_luar_layers_sims_ablated, q_labels, t_labels)\n",
    "        results.append(['MLUAR-{}'.format(selector), domain, mluar_eer, mluar_mrr])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78dfc8-11d7-48f8-9af4-9a3cdec42d27",
   "metadata": {},
   "source": [
    "### Evaluating on HRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad7c6f61-ef6c-436a-ae39-34af5bacbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.sanity = None\n",
    "params.dataset_name = 'hrs'\n",
    "params.q_author_clm_name='authorIDs'\n",
    "params.c_author_clm_name='authorSetIDs'\n",
    "params.token_max_length=32\n",
    "params.text_key = 'fullText'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34891b35-c5bd-4efc-a703-328fe9603513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map d3175716-caaf-654e-8fa1-e75a4af557ec --> 550d7750-f0fa-57dc-95d7-ef61b6fc096b\n",
      "map d6b91159-3354-f7af-aa90-7b458f173bfb --> a0fecc59-2fef-572e-a698-3c67a3ebc212\n",
      "map e4c148e3-adef-8ba6-7bc1-99d815cfebb0 --> 61224409-9987-53ea-bb5e-4f52e719fbe3\n",
      "map 0884230b-c3a1-5d7d-36cb-4eac079587fc --> 828fe9e6-a97d-58ea-bb02-e28fb580cf54\n",
      "map 12739ffb-fd89-e8ca-ab05-b341d33b1e34 --> 2bd046b3-7c09-52c4-968c-b19750e295a1\n",
      "map 855ffe07-828a-d746-c165-aa61ee4ca5bc --> 61224409-9987-53ea-bb5e-4f52e719fbe3\n",
      "map 2aaaee8a-72bb-8100-5e21-10cc7bc3a96a --> 828fe9e6-a97d-58ea-bb02-e28fb580cf54\n",
      "map 4d2d8527-e028-2686-e44d-900eeaa77d06 --> 828fe9e6-a97d-58ea-bb02-e28fb580cf54\n",
      "map 6afdb97a-d5df-e768-7cf9-9f6ddbb5d6f3 --> ccf55b4e-5751-5279-9088-c742db36d3a1\n",
      "map a213116e-1e14-4762-3ab6-14e761b372b4 --> 2e4f14ac-f53c-5eba-b8f6-6ca245948d49\n",
      "map dd4b6dc5-b888-eb29-6653-26b499708d0b --> 966baafa-ee5b-526c-9aed-7ed331eb0a52\n",
      "map a070dc13-5e22-b546-1b9e-d351f7e2eacb --> 8149c230-ee1e-5628-98a6-9510a6bbae6d\n",
      "map 7c678fb5-1464-32b0-fbd8-4e04da57e87e --> 51678012-f16c-57ce-a425-3bfe032c7572\n",
      "map f4bf2b57-27cf-5ea0-7152-468965754a08 --> 0739b9a7-72f3-5a29-ad4e-5f42e804b1ac\n",
      "map 539af952-817e-d5d5-03cf-5d4a70a124bc --> 8149c230-ee1e-5628-98a6-9510a6bbae6d\n",
      "map 964d8547-79d8-2900-8ba3-b1d2b564e6e4 --> d7a0ed96-a9b1-5082-b2b7-da488bd936c1\n",
      "map 32e3766e-f114-d6c9-1ed3-3ab272d5672f --> 3250efef-e331-5ec7-9358-895bafd52d99\n",
      "map d53e9f35-4c07-3b87-43fc-d52e5f127c6c --> ab4220c8-428b-5c81-8796-07b6c2883d56\n",
      "map 628dd294-c830-cc0d-039b-636fdc3518ad --> 3250efef-e331-5ec7-9358-895bafd52d99\n",
      "map 5dde17e0-0732-b702-3499-2f6b62b39fa4 --> d7a0ed96-a9b1-5082-b2b7-da488bd936c1\n",
      "map c756fe1c-1df5-ea15-2aa8-1537ff93292b --> 287069e8-8507-5e74-897b-151a71d40e1e\n",
      "map 1516a5c6-5a45-7fc6-46ba-8d6a713c3e29 --> 3250efef-e331-5ec7-9358-895bafd52d99\n",
      "map f0d0135a-34db-73b4-c7ff-748d8a5c9aa1 --> 51678012-f16c-57ce-a425-3bfe032c7572\n",
      "map bfce24fc-8b32-1a2d-6de8-d7c9fdfa4f27 --> 51678012-f16c-57ce-a425-3bfe032c7572\n",
      "map 12a4bf17-8595-3426-f3f3-d552a6eb3ce3 --> 6e247598-aeb5-5ff8-8433-265b0c7ac9d7\n",
      "map 07a9a4f0-faed-9b92-fd68-8f47cdc969d5 --> 9265b1f9-31f5-58e5-bfb7-c5979de68d47\n",
      "map 42628ed1-a013-748a-1cda-9ad1f86b2ef3 --> 5e00ea8b-fa2b-5956-a978-d23b952724bb\n",
      "map 07bd7fb4-b8f6-b268-5615-32e34d82c0c1 --> 4cb3e91e-ea3c-5c39-b8a2-ace64dba3914\n",
      "map e4a0428f-6323-ed56-242a-ebbb32f6c575 --> 9265b1f9-31f5-58e5-bfb7-c5979de68d47\n",
      "map ce135c32-aaab-0908-5bc2-62e6202cf87d --> 9265b1f9-31f5-58e5-bfb7-c5979de68d47\n",
      "map 6aef7aae-d4b2-b938-a294-d1dec89f9132 --> 3d04f6f7-2a4c-5a21-96f9-99927f66a99c\n",
      "map 31a56f70-8581-6e0d-9ef8-adcfef5e0dfd --> 0dbf1fcd-7396-576b-b62b-06cbd2bcfcc4\n",
      "map e3ff182b-d337-e841-02b3-d949bcf6299a --> b751926e-b0a3-508b-a49a-b9b81bb9dfdf\n",
      "map b9a4b091-3dd9-4ab1-8dab-afdc358cc797 --> 337e3dcd-c44a-5f82-ab57-3715a1793367\n",
      "map 82805940-fa84-74f5-cba6-83f5dd2dbca2 --> 337e3dcd-c44a-5f82-ab57-3715a1793367\n",
      "map 49a9d248-75b9-50d2-42f9-6fb9c0ce8b3b --> 0d1d652f-e0fc-5173-8087-717f2b789f0b\n",
      "map 2cfa03de-5856-4058-e62e-5c37af7f9a8b --> 0dbf1fcd-7396-576b-b62b-06cbd2bcfcc4\n",
      "map b8fcf8ec-1079-d0f8-aaef-444739925e1a --> 313371ec-9802-5f3f-ade0-0c75e9ad6749\n",
      "map 42532156-0da8-d477-18ee-7e212c5204a1 --> 3c832879-6a53-59e6-902c-0431ace50621\n",
      "map d9fa205f-53dc-535c-9635-449e9eeb7d90 --> a41299c1-47c6-5038-a53b-cd9316da9263\n",
      "map 8086130f-5006-33f1-587a-2a40f6b15b6a --> 6a9169ad-616c-5a65-85b3-9cf794a21634\n",
      "map 7c207489-657c-63ec-2967-f4c114278253 --> 93fe14f3-f03d-5cf5-8e5b-b7db411e0778\n",
      "map 1dbd3c27-db7b-fa68-979d-1e7802ca19eb --> 3f1ef112-9960-5239-a3cf-10050de7c5cb\n",
      "map fba4c4db-d833-d668-ec09-00e208af2d01 --> 6a9169ad-616c-5a65-85b3-9cf794a21634\n",
      "map 174e4ee1-7983-5739-a5af-a3b05481e0f9 --> 7875c972-d1c7-5506-a822-8a2d1503fc4f\n",
      "map fa743be2-2d8e-8226-6c2c-817261dd6697 --> 2c34dc9a-0e6e-5ab8-857c-3e14437e739c\n",
      "map e0f51302-4bdf-6215-b119-1975a2c12e67 --> 7875c972-d1c7-5506-a822-8a2d1503fc4f\n",
      "map 482f79c1-fccc-2a4e-22d2-fad07e217569 --> 3c832879-6a53-59e6-902c-0431ace50621\n",
      "map 41ce2a13-75bf-70ce-1a75-f19f4c18e5a3 --> 1204e318-9aff-514b-9c14-6344558268c2\n",
      "map ee5a3f3d-e0f6-72fa-4e03-7b2b0a1726c9 --> 7875c972-d1c7-5506-a822-8a2d1503fc4f\n",
      "map f7c993a7-b715-4e88-b961-06924b5dedad --> 2c34dc9a-0e6e-5ab8-857c-3e14437e739c\n",
      "map 8793c273-3ffd-7104-10a6-84186cd5f244 --> a41299c1-47c6-5038-a53b-cd9316da9263\n",
      "map 818beeb1-f400-b6b9-e5b9-4bc49b61120e --> 93fe14f3-f03d-5cf5-8e5b-b7db411e0778\n",
      "map b971ccfb-2c2e-28ef-31d5-7009a6a1bdec --> 3f1ef112-9960-5239-a3cf-10050de7c5cb\n",
      "map 3a7d5b56-4fc6-f54d-f3a2-dd87adaa95b3 --> 69d222c6-f590-5636-879e-936c9d7cf2c8\n",
      "map 484f4820-5b8e-59d1-883e-3d73661cb21f --> 4d3d58ef-7ea3-537b-a7ad-313443d4d9ff\n",
      "map 1d2e5f27-0548-3e75-c262-879f117be00a --> 1ab028b1-f57e-54cd-a0df-8330ac93264f\n",
      "map 12a6cac9-9eb1-bb10-9917-28aea9cc69fd --> 91ba9fcd-3998-5f6f-92c9-1bd796912d96\n",
      "map 1ef75f83-f7e8-0767-fea3-ac0d683bafbe --> 91ba9fcd-3998-5f6f-92c9-1bd796912d96\n",
      "map 5da5bb5b-cfbe-45ea-8a11-6af8d70f131d --> 0dd754fa-c0dd-53ee-8d8b-f537f17d219b\n",
      "map 7f316a3e-645d-e5a6-51c3-283aa31a0565 --> 3dcf7603-cae9-5d6c-b4f3-2db38dfca004\n",
      "map 9e3e234e-7b75-b79a-53b5-24d8886ef4af --> cd5df6fb-86d1-5634-af52-85e8754fa576\n",
      "map 76e0d068-ce2f-e3e1-bff4-edf1cd45a658 --> 420c277d-53c7-5c9b-a713-254bed56b10c\n",
      "map 45bd18d5-2b31-358c-2135-7f81fefa32f4 --> 1c748e8e-6b95-5f81-a6d0-d333fd28583a\n"
     ]
    }
   ],
   "source": [
    "params.dataset_path = '/mnt/swordfish-pool2/milad/hiatus-data/HRS_evaluation_samples/HRS1_english_long/TA2/HRS1_english_long_sample-0_crossGenre/'\n",
    "params.queries_file_name = 'data/HRS1_english_long_sample-0_crossGenre_TA2_input_queries.jsonl'\n",
    "params.gt_path = 'groundtruth/HRS1_english_long_sample-0_crossGenre_TA2'\n",
    "params.candidates_file_name = 'data/HRS1_english_long_sample-0_crossGenre_TA2_input_candidates.jsonl'\n",
    "\n",
    "hrs_q_loader, hrs_t_loader, hrs_q_ds, hrs_t_ds = test_dataloader(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d63c565e-aeb5-4973-ba33-f961116b7ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:12,  3.35it/s]\n",
      "64it [00:15,  4.10it/s]\n"
     ]
    }
   ],
   "source": [
    "q_luar_embeddings, q_mluar_embeddings, q_author_labels = get_embeddings(hrs_q_loader)\n",
    "t_luar_embeddings, t_mluar_embeddings, t_author_labels = get_embeddings(hrs_t_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5128cd64-d543-4c68-b8b0-cd7f94b7187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_author_labels = [hrs_q_ds.int2AuthorId[x.item()] for x in q_author_labels]\n",
    "t_author_labels = [hrs_t_ds.int2AuthorId[x.item()] for x in t_author_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dde13735-8c44-4ef3-806f-b909275836f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = evaluate_embeddings(q_luar_embeddings, t_luar_embeddings, q_mluar_embeddings, t_mluar_embeddings, q_author_labels, t_author_labels, domain = 'hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d92b507-36c2-4833-b4d8-1244f33d3d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Domain    EER    MRR\n",
      "---------------  --------  -----  -----\n",
      "LUAR             hrs       0.375  0.135\n",
      "+++              +++       +++    +++\n",
      "MLUAR            hrs       0.453  0.112\n",
      "--               --        --     --\n",
      "MLUAR-[0, 1]     hrs       0.471  0.101\n",
      "MLUAR-[0, 1, 2]  hrs       0.466  0.109\n",
      "MLUAR-[3, 4, 5]  hrs       0.422  0.13\n",
      "MLUAR-[5, 6]     hrs       0.438  0.126\n",
      "MLUAR-[6]        hrs       0.436  0.128\n"
     ]
    }
   ],
   "source": [
    "#Note that these results are not on the full haystack (In line 102 in the hrs_dataset.py, I only kept the candidate authors that are matched with the query authors)\n",
    "print(tabulate.tabulate(results, headers=['Domain', 'EER', 'MRR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f8afa2c-cebc-4664-9c2d-12254303567a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map 4f94add8-5b2f-5cb1-8ad2-008772603e94 --> 1c05f9d5-16fa-50e6-85f6-a81da55766fc\n",
      "map e74bdae6-b163-a908-0e98-d8930d066717 --> 1c05f9d5-16fa-50e6-85f6-a81da55766fc\n",
      "map 2a0f608b-d5e8-8f6e-7bd9-a4380567644e --> 3353a8da-edac-5584-bcac-c8607954d040\n",
      "map 1757e209-3119-b197-3763-22f5d66be1b2 --> 1c05f9d5-16fa-50e6-85f6-a81da55766fc\n",
      "map 76f68fbb-4c39-6292-3156-1b55fe5beb55 --> 3353a8da-edac-5584-bcac-c8607954d040\n",
      "map 123d54e9-4246-c538-1a24-993f24179cdd --> dfa7d505-10c2-54a7-bfd5-5e0b32e8711e\n",
      "map ece9374f-5cfd-358e-fa5c-2c6a1af63cf4 --> 1c05f9d5-16fa-50e6-85f6-a81da55766fc\n",
      "map 01075158-d1da-c3af-a71e-681385ba46ca --> 3353a8da-edac-5584-bcac-c8607954d040\n",
      "map c5ee9c03-2aa0-f69d-523b-04d36902e6a9 --> 8568f101-9281-5aad-9a09-ddb08535e583\n",
      "map ad61e2d0-1eff-2161-7ad2-f73c46f62946 --> 1f4e6a77-857b-5774-a2d1-50b1bc12af60\n",
      "map fd8ee89f-ce89-e5bc-e3d2-0090bc9f9b53 --> 8568f101-9281-5aad-9a09-ddb08535e583\n",
      "map 2dc9a9e3-dfe0-1c9d-b7fe-6dc4db06868c --> 1f4e6a77-857b-5774-a2d1-50b1bc12af60\n",
      "map 8fe09888-ffd8-2216-f5be-97f7fa9cdb75 --> a5bdc14c-bf27-51fc-930d-a78969ba45ff\n",
      "map 7032e011-e4fb-6822-7929-54eab9c17f9e --> 65d20216-381d-59b0-9aad-da62b34b4af4\n",
      "map 58c0d006-d082-fc5b-a995-0ae3854eda9f --> 8568f101-9281-5aad-9a09-ddb08535e583\n",
      "map 0ee490de-14b4-7f2e-e663-52ac83a7d2c5 --> 8568f101-9281-5aad-9a09-ddb08535e583\n",
      "map 4d954ae4-63eb-86f3-fd5c-b74648b3b8ce --> 1f4e6a77-857b-5774-a2d1-50b1bc12af60\n",
      "map bcd1a529-3165-2cf8-b7d4-fe792c8ae1bf --> 65d20216-381d-59b0-9aad-da62b34b4af4\n",
      "map 25c6b125-2e3b-da7d-856c-c49e6a472029 --> 0b4f8e44-22d3-528a-939c-7343e14f9af5\n",
      "map 40981713-7809-4f59-6f7d-48f082ac5b22 --> 65d20216-381d-59b0-9aad-da62b34b4af4\n",
      "map b2f2d6b1-82f6-0739-5efa-5678f0d75595 --> 00f988f5-3606-5946-9380-c82e18c1bd08\n",
      "map 00c35616-0cd9-def4-026d-10b52ec9a636 --> 00f988f5-3606-5946-9380-c82e18c1bd08\n",
      "map c02b46c3-be23-4c04-b744-208013895b00 --> 00f988f5-3606-5946-9380-c82e18c1bd08\n",
      "map b1697b30-bad4-9ead-1ec3-b2c0bfdecf5c --> 00f988f5-3606-5946-9380-c82e18c1bd08\n",
      "map fb109919-4a6d-c88e-7ab2-90d778041ede --> 65d20216-381d-59b0-9aad-da62b34b4af4\n",
      "map a6dc8663-13eb-a704-1289-778556573612 --> 66e6eb57-5029-5299-a14c-b07e5910a38c\n",
      "map 335ddb30-a1e7-0608-af2e-a83feb7a4e7a --> 94e69f61-c9a7-5d8c-ac0f-7ee7d1a55d7d\n",
      "map 5c4f6ad9-4eed-4647-6bd3-7680381c25ad --> 46a605d6-9174-5557-9f0f-8734a8cd3f93\n",
      "map 70d79d9e-69fb-d55a-ff7a-d8471386e6e0 --> 46a605d6-9174-5557-9f0f-8734a8cd3f93\n",
      "map e5d1411a-b272-6b89-8560-ad2d2f655566 --> 46a605d6-9174-5557-9f0f-8734a8cd3f93\n",
      "map c5a62569-7739-8c4a-6e99-f406d042ef98 --> 94e69f61-c9a7-5d8c-ac0f-7ee7d1a55d7d\n",
      "map 5120e55b-12df-6c59-5302-0b1f64fb2a03 --> 66e6eb57-5029-5299-a14c-b07e5910a38c\n",
      "map 4a111102-fc3f-c47a-1e8c-11394d4e164b --> 94e69f61-c9a7-5d8c-ac0f-7ee7d1a55d7d\n",
      "map 0393d754-471c-1add-3dc2-3d3378fd7a0b --> 66e6eb57-5029-5299-a14c-b07e5910a38c\n",
      "map 137f7b60-6275-fb10-49d9-32293703dc0e --> 162b5136-6c30-5a74-902f-21f9051e32d8\n",
      "map 724b4233-9896-ec59-8612-041717d3294a --> 162b5136-6c30-5a74-902f-21f9051e32d8\n",
      "map 907f636d-53c0-e846-b1a6-fa1a2e597a68 --> 0a83e635-b81f-5513-bf71-bc1e27fe7f67\n",
      "map feb0590a-6031-75bb-d5ff-331b40def67e --> ed5869f0-1d7e-5297-a66d-597d3d5af8ea\n",
      "map 9b8f77a6-2d9c-7960-3e24-1ec9b4987fc9 --> de5e331d-c97f-50fe-a228-d6669b2e7148\n",
      "map 20e9adf7-fc23-c0ad-1622-11615f9af39d --> de5e331d-c97f-50fe-a228-d6669b2e7148\n",
      "map 72d68d77-314a-41e2-6b0b-4dd5cd5dab5f --> ed5869f0-1d7e-5297-a66d-597d3d5af8ea\n",
      "map 90b27fc1-eafa-4c18-3701-ad92914b80c4 --> 7699df66-863f-5c8e-9801-704868a3822d\n",
      "map ad5f2d16-3f00-57c6-5351-6e024514551c --> 7699df66-863f-5c8e-9801-704868a3822d\n",
      "map db2ca675-e3dd-e1f2-18cc-3086f1fb399e --> df89d48a-c4b0-5545-9492-830dcc9ca8bf\n",
      "map c022b23a-1451-6273-1847-39ac85e9856a --> 45e6c7aa-7d39-57c3-a1f9-6f32d6fb0b4e\n",
      "map 3bc026c8-c3ac-b6cd-221c-6db03c7b26b3 --> 45e6c7aa-7d39-57c3-a1f9-6f32d6fb0b4e\n",
      "map 7d4c4d2b-fa95-cef0-db6f-d4a154603823 --> df89d48a-c4b0-5545-9492-830dcc9ca8bf\n",
      "map fa112686-4e36-41ed-f216-5144922732fd --> 157e8585-08a9-5437-9ef1-978f365814ff\n",
      "map 673d2963-0d96-2c9d-8913-803c1bb80b11 --> df89d48a-c4b0-5545-9492-830dcc9ca8bf\n",
      "map 0ca14468-3cd5-078d-41a1-6bc66a9eff62 --> 157e8585-08a9-5437-9ef1-978f365814ff\n",
      "map 71eb1b9e-f86a-1dd4-6448-735fcba8daaf --> df89d48a-c4b0-5545-9492-830dcc9ca8bf\n",
      "map a04e95cb-468a-f6e4-ffbc-503528544a73 --> 7699df66-863f-5c8e-9801-704868a3822d\n",
      "map 6824b7c3-0e97-3e2b-1cd2-ecea45788a58 --> ed60771f-460b-57f8-bcdc-76abae8ae3a9\n",
      "map 67a826b9-fa23-ad54-8408-dd04b185dade --> 45e6c7aa-7d39-57c3-a1f9-6f32d6fb0b4e\n",
      "map c49037d1-8d1a-25cb-e980-0b27dbb69d30 --> ed60771f-460b-57f8-bcdc-76abae8ae3a9\n",
      "map 20887aa0-4025-4702-1ea8-0845877d2af6 --> 157e8585-08a9-5437-9ef1-978f365814ff\n",
      "map 35fee35c-4ab3-32b5-ece9-8e394354c08c --> 7699df66-863f-5c8e-9801-704868a3822d\n"
     ]
    }
   ],
   "source": [
    "params.dataset_path = '/mnt/swordfish-pool2/milad/hiatus-data/HRS_evaluation_samples/HRS2_english_medium/TA2/HRS2_english_medium_sample-0_crossGenre/'\n",
    "params.queries_file_name = 'data/HRS2_english_medium_sample-0_crossGenre_TA2_input_queries.jsonl'\n",
    "params.gt_path = 'groundtruth/HRS2_english_medium_sample-0_crossGenre_TA2'\n",
    "params.candidates_file_name = 'data/HRS2_english_medium_sample-0_crossGenre_TA2_input_candidates.jsonl'\n",
    "\n",
    "hrs_q_loader, hrs_t_loader, hrs_q_ds, hrs_t_ds = test_dataloader(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d669f565-ea22-4c59-88bb-a496fba4e5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:04,  4.36it/s]\n",
      "57it [00:09,  5.86it/s]\n"
     ]
    }
   ],
   "source": [
    "q_luar_embeddings, q_mluar_embeddings, q_author_labels = get_embeddings(hrs_q_loader)\n",
    "t_luar_embeddings, t_mluar_embeddings, t_author_labels = get_embeddings(hrs_t_loader)\n",
    "\n",
    "q_author_labels = [hrs_q_ds.int2AuthorId[x.item()] for x in q_author_labels]\n",
    "t_author_labels = [hrs_t_ds.int2AuthorId[x.item()] for x in t_author_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78bcce03-cd01-417e-bc36-e3282e7fb5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Domain    EER    MRR\n",
      "---------------  --------  -----  -----\n",
      "LUAR             hrs       0.386  0.289\n",
      "+++              +++       +++    +++\n",
      "MLUAR            hrs       0.407  0.199\n",
      "--               --        --     --\n",
      "MLUAR-[0, 1]     hrs       0.421  0.144\n",
      "MLUAR-[0, 1, 2]  hrs       0.421  0.153\n",
      "MLUAR-[3, 4, 5]  hrs       0.439  0.233\n",
      "MLUAR-[5, 6]     hrs       0.419  0.231\n",
      "MLUAR-[6]        hrs       0.405  0.245\n"
     ]
    }
   ],
   "source": [
    "#Note that these results are not on the full haystack (In line 102 in the hrs_dataset.py, I only kept the candidate authors that are matched with the query authors)\n",
    "results = evaluate_embeddings(q_luar_embeddings, t_luar_embeddings, q_mluar_embeddings, t_mluar_embeddings, q_author_labels, t_author_labels, domain = 'hrs')\n",
    "print(tabulate.tabulate(results, headers=['Domain', 'EER', 'MRR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106c4cf-05d2-4193-a48c-3c97295a0f46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluating on Fanfiction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e2bc1ec-ec22-44d8-a70c-28ab63a89ec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = create_argument_parser()\n",
    "#params.sanity = 100\n",
    "params.sanity = None\n",
    "params.episode_length=16\n",
    "params.model_type='roberta'\n",
    "params.text_key = 'syms'\n",
    "params.time_key='hours'\n",
    "params.suffix=''\n",
    "params.token_max_length=32\n",
    "params.use_random_windows=False\n",
    "params.mask_bpe_percentage=0\n",
    "params.pin_memory=False\n",
    "params.num_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aac65d95-4a4c-4acf-abd3-4a4bbd007424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pan_paragraph dataset test query file: /mnt/swordfish-pool2/nikhil/pan_paragraph/train_raw.jsonl\n",
      "Loading pan_paragraph dataset test targets file: /mnt/swordfish-pool2/nikhil/pan_paragraph/train_raw.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:18,  1.80s/it]\n",
      "10it [00:18,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "params.dataset_name = 'pan_paragraph'\n",
    "pan_paragraph_q_loader, pan_paragraph_t_loader, hrs_q_ds, hrs_t_ds = test_dataloader(params)\n",
    "q_luar_embeddings, q_mluar_embeddings, q_author_labels = get_embeddings(pan_paragraph_q_loader)\n",
    "t_luar_embeddings, t_mluar_embeddings, t_author_labels = get_embeddings(pan_paragraph_t_loader)\n",
    "\n",
    "q_author_labels = [x.item() for x in q_author_labels]\n",
    "t_author_labels = [x.item() for x in t_author_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da84c826-1b8a-4c45-923f-5a03cfa93f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = evaluate_embeddings(q_luar_embeddings, t_luar_embeddings, q_mluar_embeddings, t_mluar_embeddings, q_author_labels, t_author_labels, domain = 'pan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10931417-6fe0-459d-95dc-0e29318e3869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Domain        EER    MRR\n",
      "---------------  ------------  -----  -----\n",
      "LUAR             pan           0.169  0.323\n",
      "+++              +++           +++    +++\n",
      "MLUAR            pan           0.105  0.463\n",
      "--               --            --     --\n",
      "MLUAR-[0, 1]     cross-domain  0.146  0.397\n",
      "MLUAR-[0, 1, 2]  cross-domain  0.135  0.412\n",
      "MLUAR-[3, 4, 5]  cross-domain  0.097  0.472\n",
      "MLUAR-[5, 6]     cross-domain  0.094  0.476\n",
      "MLUAR-[6]        cross-domain  0.094  0.474\n"
     ]
    }
   ],
   "source": [
    "print(tabulate.tabulate(results, headers=['Domain', 'EER', 'MRR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92643da-5bb7-4584-a221-aeb7791d3c94",
   "metadata": {},
   "source": [
    "### Evaluating on Amazon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f8d62b-3508-463b-ae9c-fd3270088c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw_amazon dataset test query file: /mnt/swordfish-pool2/nikhil/raw_amazon/validation_queries.jsonl\n",
      "Loading raw_amazon dataset test targets file: /mnt/swordfish-pool2/nikhil/raw_amazon/validation_targets.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "10001it [24:53,  6.70it/s]\n",
      "10001it [26:23,  6.31it/s]\n"
     ]
    }
   ],
   "source": [
    "params.dataset_name = 'raw_amazon'\n",
    "amazon_paragraph_q_loader, amazon_paragraph_t_loader = test_dataloader(params)\n",
    "q_luar_embeddings, q_mluar_embeddings, q_author_labels = get_embeddings(amazon_paragraph_q_loader)\n",
    "t_luar_embeddings, t_mluar_embeddings, t_author_labels = get_embeddings(amazon_paragraph_t_loader)\n",
    "\n",
    "q_author_labels = [x.item() for x in q_author_labels]\n",
    "t_author_labels = [x.item() for x in t_author_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf4eb0b-85bf-410e-b21c-6c2f9efbc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_embeddings(q_luar_embeddings, t_luar_embeddings, q_mluar_embeddings, t_mluar_embeddings, q_author_labels, t_author_labels, domain = 'amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "046c5b25-4fbf-4dd4-b533-408ca4cb9ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Domain    EER    MRR\n",
      "-----  --------  -----  -----\n",
      "LUAR   amazon    0.062  0.534\n",
      "+++    +++       +++    +++\n",
      "MLUAR  amazon    0.02   0.784\n",
      "--     --        --     --\n"
     ]
    }
   ],
   "source": [
    "print(tabulate.tabulate(results, headers=['Domain', 'EER', 'MRR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2138f1d-b68c-4cc4-af37-3c3e2acb22ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
