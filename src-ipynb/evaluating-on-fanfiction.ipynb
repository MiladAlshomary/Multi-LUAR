{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98add410-2397-4016-a873-968289bfacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39967725-2cd2-4da3-8e97-79546fd8626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f92b73-a37d-443b-90ac-e6f131417e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utilities.mluar_utils import *\n",
    "from src.datasets import utils\n",
    "from src.arguments import create_argument_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68524a3c-6085-46ff-8639-45985108e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce, repeat\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import pickle as pkl\n",
    "import tabulate\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5979105-cb91-4941-a198-4cf18e2f5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = create_argument_parser()\n",
    "params.sanity = None\n",
    "params.episode_length=16\n",
    "params.model_type='roberta'\n",
    "params.text_key = 'syms'\n",
    "params.time_key='hours'\n",
    "params.suffix=''\n",
    "params.token_max_length=32\n",
    "params.mask_bpe_percentage=0\n",
    "params.pin_memory=False\n",
    "params.num_workers=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61abce0-9a44-4819-9999-27578cc60775",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_LUAR_PATH =  \"/mnt/swordfish-pool2/milad/multi-luar-reddit-model/\"\n",
    "LUAR_PATH =  \"/mnt/swordfish-pool2/nikhil/LUAR/pretrained_weights/LUAR-MUD/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc7098f-1fd3-42e8-bcec-af94d8211d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "multiluar_model = AutoModel.from_pretrained(MULTI_LUAR_PATH, trust_remote_code=True)\n",
    "luar_model = AutoModel.from_pretrained(LUAR_PATH, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rrivera1849/LUAR-MUD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5e883083-2487-4206-b7aa-7062916e01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_collate_fn(batch):\n",
    "    \"\"\"Some validation datasets have authors with less than < 16 episodes. \n",
    "       When batching, make sure that we don't run into stacking problems. \n",
    "    \"\"\"\n",
    "\n",
    "    data, author = zip(*batch)\n",
    "\n",
    "    author = torch.stack(author)\n",
    "\n",
    "    # Minimum number of posts for an author history in batch\n",
    "    min_posts = min([d[0].shape[1] for d in data])\n",
    "    # If min_posts < episode length, need to subsample\n",
    "    if min_posts < 16:\n",
    "        data = [torch.stack([f[:, :min_posts, :] for f in feature])\n",
    "                for feature in zip(*data)]\n",
    "    # Otherwise, stack data as is\n",
    "    else:\n",
    "        data = [torch.stack([f for f in feature])\n",
    "                for feature in zip(*data)]\n",
    "\n",
    "    return data, author\n",
    "\n",
    "def test_dataloader(params):\n",
    "    \"\"\"Returns the validation DataLoader.\n",
    "    \"\"\"\n",
    "    # to counteract different episode sizes during validation / testing\n",
    "    batch_size = 1 if params.dataset_name in [\"raw_amazon\", \"pan_paragraph\"] else params.batch_size\n",
    "    \n",
    "    queries = utils.get_val_or_test_dataset(params, 'test', only_queries=True)\n",
    "\n",
    "    data_loaders = [\n",
    "        DataLoader(\n",
    "            queries,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=params.pin_memory,\n",
    "            num_workers=params.num_workers,\n",
    "            #collate_fn=validation_collate_fn\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    return data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "312ce32d-b8ed-44c0-abbd-6e91784a9d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(test_data_loader, num_samples=100000):\n",
    "    luar_embeddings = []\n",
    "    mluar_embeddings = []\n",
    "    author_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_data_loader[0]):\n",
    "            data, author = batch[0], batch[1]\n",
    "            \n",
    "            luar_embedding = luar_model(data[0].squeeze(0), data[1].squeeze(0))\n",
    "            luar_embeddings.append(luar_embedding)\n",
    "        \n",
    "            mluar_embedding = multiluar_model(data[0].squeeze(0), data[1].squeeze(0))\n",
    "            mluar_embedding = rearrange(mluar_embedding, 'l b d -> b l d')\n",
    "            mluar_embeddings.append(mluar_embedding)\n",
    "    \n",
    "            author_labels.append(author)\n",
    "            if i > num_samples:\n",
    "                break\n",
    "        luar_embeddings = torch.stack(luar_embeddings)\n",
    "        mluar_embeddings = torch.stack(mluar_embeddings).squeeze(1)\n",
    "\n",
    "    return luar_embeddings, mluar_embeddings, author_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac65d95-4a4c-4acf-abd3-4a4bbd007424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pan_paragraph dataset test query file: /mnt/swordfish-pool2/nikhil/pan_paragraph/queries_raw.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "params.dataset_name = 'pan_paragraph'\n",
    "pan_paragraph_loader = test_dataloader(params)\n",
    "luar_embeddings, mluar_embeddings, author_labels = get_embeddings(pan_paragraph_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "df2794b9-162a-4df2-a86d-81219c955b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "504971d4-5580-4836-b06b-26404421660d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n",
      "[0, 2, 3, 4, 5, 6]\n",
      "[0, 1, 3, 4, 5, 6]\n",
      "[0, 1, 2, 4, 5, 6]\n",
      "[0, 1, 2, 3, 5, 6]\n",
      "[0, 1, 2, 3, 4, 6]\n",
      "[0, 1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/mnt/swordfish-pool2/milad/conda-envs/huggingface-tlr/lib/python3.13/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "domain = 'pan'\n",
    "\n",
    "luar_sims = compute_similarities(luar_embeddings, luar_embeddings)\n",
    "labels_matrix = np.array([[int(x == y) for y in author_labels] for x in author_labels])\n",
    "luar_eer, luar_mrr   = eer(luar_sims, labels_matrix), compute_mrr(luar_sims, author_labels)\n",
    "\n",
    "results.append(['LUAR', domain, luar_eer, luar_mrr])\n",
    "results.append(['+++', '+++', '+++', '+++'])\n",
    "\n",
    "muti_luar_layers_sims = np.stack([compute_similarities(mluar_embeddings, mluar_embeddings, layer=i) for i in range(7)])\n",
    "\n",
    "muti_luar_layers_sims_ablated = np.mean(muti_luar_layers_sims, 0)\n",
    "mluar_eer, mluar_mrr = eer(muti_luar_layers_sims_ablated, labels_matrix), compute_mrr(muti_luar_layers_sims_ablated, author_labels)\n",
    "results.append(['MLUAR', domain, mluar_eer, mluar_mrr])\n",
    "results.append(['--', '--', '--', '--'])\n",
    "\n",
    "# Ablation study\n",
    "for layer in range(7):\n",
    "    selector = [i for i in range(muti_luar_layers_sims.shape[0]) if i != layer]\n",
    "    print(selector)\n",
    "    muti_luar_layers_sims_ablated = np.mean(muti_luar_layers_sims[selector, :, :], 0)\n",
    "    mluar_eer, mluar_mrr = eer(muti_luar_layers_sims_ablated, labels_matrix), compute_mrr(muti_luar_layers_sims_ablated, author_labels)\n",
    "    results.append(['MLUAR/{}'.format(layer), domain, mluar_eer, mluar_mrr])\n",
    "    results.append(['--', '--', '--', '--'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "29eea14e-c98d-4329-b497-12fc19a4ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Domain    EER    MRR\n",
      "-------  --------  -----  -----\n",
      "LUAR     pan       0.0    nan\n",
      "+++      +++       +++    +++\n",
      "MLUAR    pan       0.0    nan\n",
      "--       --        --     --\n",
      "MLUAR/0  pan       0.0    nan\n",
      "--       --        --     --\n",
      "MLUAR/1  pan       0.0    nan\n",
      "--       --        --     --\n",
      "MLUAR/2  pan       0.0    nan\n",
      "--       --        --     --\n",
      "MLUAR/3  pan       0.0    nan\n",
      "--       --        --     --\n",
      "MLUAR/4  pan       0.0    nan\n",
      "--       --        --     --\n",
      "MLUAR/5  pan       0.0    nan\n",
      "--       --        --     --\n",
      "MLUAR/6  pan       0.0    nan\n",
      "--       --        --     --\n"
     ]
    }
   ],
   "source": [
    "print(tabulate.tabulate(results, headers=['Domain', 'EER', 'MRR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdb86b-71e8-4cf9-b39e-672439e9e172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
